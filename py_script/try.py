import torch
import numpy as np
from torch.nn.functional import softmax
if __name__=="__main__":
    # a=torch.tensor([[5.2889e-04, 1.0543e-04, 2.7113e-04, 3.7351e-03, 1.5591e-03, 6.0300e-03,
    #     1.0286e-04, 6.6956e-03, 4.4695e-03, 2.1336e-03, 4.5835e-04, 3.0544e-04,
    #     7.9182e-05, 3.5140e-03, 2.1838e-05, 1.0682e-05, 4.7050e-04, 3.8905e-04,
    #     2.0204e-05, 1.3600e-03, 8.7296e-05, 7.3631e-06, 4.8614e-05, 9.1984e-01,
    #     2.1418e-04, 2.8644e-04, 1.4598e-02, 1.2447e-02, 9.1102e-04, 1.2822e-02,
    #     7.6507e-04, 2.8093e-03, 2.4842e-03, 7.6914e-05, 1.7141e-04, 1.1419e-04,
    #     5.5893e-05],[5.7998e-04, 6.8545e-04, 2.5494e-02, 3.8073e-03, 1.8662e-05, 1.9068e-03,
    #     1.2849e-04, 9.8366e-04, 1.9308e-03, 1.9123e-03, 5.3038e-04, 6.9843e-02,
    #     1.6267e-04, 2.4566e-04, 1.2281e-03, 4.1301e-03, 4.8907e-05, 8.2183e-06,
    #     2.0179e-05, 3.0387e-03, 3.6784e-03, 9.0673e-05, 4.1258e-03, 7.6406e-05,
    #     8.5732e-01, 1.1729e-06, 9.4252e-04, 1.3872e-03, 1.3619e-04, 1.6145e-05,
    #     1.6777e-03, 3.5497e-05, 2.9954e-03, 1.0533e-02, 1.6932e-04, 3.5763e-05,
    #     7.2356e-05]],dtype=torch.float)
    a=torch.tensor([[0.9,0.05,0.05],[0.8,0.1,0.1],[0.7,0.15,0.15]])
    print(softmax(a))
    a=torch.div(a,10)
    print(softmax(a))
